# Distributed-Computing-MapReduce-Hadoop

Distributed Computing and Storage Architectures: Project MapReduce
Nov 2019 â€“ Dec 2019

Project descriptionIn this project, I completed tasks using MapReduce (Python MRJob) and run them on a Hadoop cluster. This project is a part of the Distributed Computing course. The tasks in the project:

IMDB TSV File:
TASK 1: Find the 50 most common keywords for all
movies and shorts. (For all entities for the type movie and short, and the top 50 most common
keywords used in the primary titles using MapReduce).

TASK 2: Top 15 keywords for each movie genre. (For each possible genre of the type movie (this excludes tv-shows, etc...) and the top 15 most common keywords within their primary titles using MapReduce).

Online Retail: The retail sales of one individual company
for two years in the form of a CSV file.
TASK 3: Top 10 best customers for both years combined. (Using MapReduce and the top 10 customers of each retail year that bought the most in terms of total revenue (quantity * price)).

TASK 4: Best selling product. (Using MapReduce and the best selling product, once in terms of the total quantity, and once in terms of total revenue for both retail years).

Similar paper recommendations: A JSON archive of meta-data on 20.000 scientific papers
on Arxiv.

TASK 5: Jaccard Similarity Coefficient. (Given a random paper summary and the paper with the closest Jaccard Distance).

TASK 6: Cosine Similarity. (Given a random paper summary and the paper with the highest Cosine Similarity score).

Matrix Multiplication
TASK 8: Matrix dot product. (Implement the matrix dot product in MapReduce).

Hadoop
TASK 9: Hadoop. (Set up a Single node Hadoop cluster, upload the assignment files to the HDFS
and validate the results of previous tasks).
